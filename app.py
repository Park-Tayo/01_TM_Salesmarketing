import streamlit as st
import pandas as pd
import openai  # OpenAIë¥¼ ì œëŒ€ë¡œ ì„í¬íŠ¸í•©ë‹ˆë‹¤
import os
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
try:
    if 'OPENAI_API_KEY' in st.secrets:
        openai_api_key = st.secrets["OPENAI_API_KEY"]
    else:
        openai_api_key = os.getenv('OPENAI_API_KEY')
        
    if not openai_api_key:
        st.error('OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.')
        st.stop()
        
    client = openai.OpenAI(api_key=openai_api_key)  # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
except Exception as e:
    st.error(f'API í‚¤ ì„¤ì • ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}')
    st.stop()

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ë¦´ìŠ¤ ê°•ì˜ Q&A ì±—ë´‡", page_icon="ğŸ¤–")

# ìŠ¤í¬ë¦½íŠ¸ ë°ì´í„° ë¡œë“œ
@st.cache_data
def load_script():
    df = pd.read_csv("ë¦´ìŠ¤ ê°•ì˜_ì •ë¦¬.csv", encoding='utf-8')
    return " ".join(df.iloc[:, 0].dropna().astype(str))

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []

def verify_response(script, question, answer):
    try:
        verification = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": """
                ë‹¹ì‹ ì€ ì—„ê²©í•œ ë‹µë³€ ê²€ì¦ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
                ì˜¤ì§ ì£¼ì–´ì§„ ë¦´ìŠ¤ ê°•ì˜ ë‚´ìš©ë§Œì„ ê¸°ì¤€ìœ¼ë¡œ ë‹µë³€ì„ ê²€ì¦í•´ì£¼ì„¸ìš”.
                ë¦´ìŠ¤ ê°•ì˜ ë‚´ìš©ì— ëª…ì‹œë˜ì§€ ì•Šì€ ë‚´ìš©ì´ ë‹µë³€ì— í¬í•¨ë˜ì–´ ìˆë‹¤ë©´ ì´ë¥¼ ë°˜ë“œì‹œ ì§€ì í•´ì£¼ì„¸ìš”.
                
                ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”:
                - ì •í™•ë„ ì ìˆ˜: (0-100)
                - íŒë‹¨ ê·¼ê±°: (ë¦´ìŠ¤ ê°•ì˜ì˜ ì–´ë–¤ ë¶€ë¶„ì„ ì°¸ê³ í–ˆëŠ”ì§€ êµ¬ì²´ì ìœ¼ë¡œ ëª…ì‹œ)
                - ê°•ì˜ë¥¼ ë²—ì–´ë‚œ ë‚´ìš©: (ë¦´ìŠ¤ ê°•ì˜ì— ì—†ëŠ” ë‚´ìš©ì´ ë‹µë³€ì— í¬í•¨ëœ ê²½ìš° ì§€ì )
                - ê°œì„  ì œì•ˆ: (í•„ìš”í•œ ê²½ìš°)
                """},
                {"role": "user", "content": f"""
                ìŠ¤í¬ë¦½íŠ¸: {script}
                ì§ˆë¬¸: {question}
                ë‹µë³€: {answer}
                """}
            ],
            temperature=0,
            max_tokens=500
        )
        return verification.choices[0].message.content
    except Exception as e:
        return f"ê²€ì¦ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

# ë©”ì¸ í•¨ìˆ˜
def main():
    st.title("ğŸ’¬ ë¦´ìŠ¤ ê°•ì˜ Q&A ì±—ë´‡")
    
    # ìŠ¤í¬ë¦½íŠ¸ ë¡œë“œ
    script = load_script()
    
    # ì‚¬ì´ë“œë°”ì— ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ í‘œì‹œ (ì„ íƒì‚¬í•­)
    with st.sidebar:
        st.header("AI ì±—ë´‡ ì •ë³´")
        st.info("ì´ AI ì±—ë´‡ì€ ì¸ìŠ¤íƒ€ê·¸ë¨ ë¦´ìŠ¤ ë§ˆì¼€íŒ… ê°•ì˜ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•©ë‹ˆë‹¤.")
        
        # ëŒ€í™” ì´ˆê¸°í™” ë²„íŠ¼
        if st.button("ëŒ€í™” ì´ˆê¸°í™”"):
            st.session_state.messages = []
            st.rerun()
    
    # ì´ì „ ëŒ€í™” ë‚´ìš© í‘œì‹œ
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
    
    # ì‚¬ìš©ì ì…ë ¥
    if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”"):
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)
            
        # AI ì‘ë‹µ ìƒì„±
        with st.chat_message("assistant"):
            with st.spinner('ë‹µë³€ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤...'):
                try:
                    messages = [
                        {"role": "system", "content": f"""
                        ë‹¹ì‹ ì€ ì£¼ì–´ì§„ ë¦´ìŠ¤ ê°•ì˜ ë‚´ìš©ë§Œì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•˜ëŠ” Q&A ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
                        
                        ì¤‘ìš”í•œ ê·œì¹™:
                        1. ì˜¤ì§ ì œê³µëœ ë¦´ìŠ¤ ê°•ì˜ì— ìˆëŠ” ë‚´ìš©ë§Œ ì‚¬ìš©í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”.
                        2. ë¦´ìŠ¤ ê°•ì˜ì— ê´€ë ¨ ë‚´ìš©ì´ ì—†ë‹¤ë©´ "ì£„ì†¡í•˜ì§€ë§Œ ì£¼ì–´ì§„ ê°•ì˜ ë‚´ìš©ì—ì„œ í•´ë‹¹ ì§ˆë¬¸ì— ëŒ€í•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ë‹µë³€í•˜ì„¸ìš”.
                        3. ë¦´ìŠ¤ ê°•ì˜ì˜ ë‚´ìš©ì„ ë²—ì–´ë‚˜ëŠ” ì¼ë°˜ì ì¸ ì¡°ì–¸ì´ë‚˜ ì¶”ì¸¡ì€ í•˜ì§€ ë§ˆì„¸ìš”.
                        4. ë‹µë³€í•  ë•ŒëŠ” ë¦´ìŠ¤ ê°•ì˜ì˜ ì–´ë–¤ ë¶€ë¶„ì„ ì°¸ê³ í–ˆëŠ”ì§€ ëª…ì‹œí•˜ë©´ì„œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
                        
                        ìŠ¤í¬ë¦½íŠ¸ ë‚´ìš©: {script}
                        """}
                    ]
                    # ì´ì „ ëŒ€í™” ë‚´ìš© í¬í•¨
                    messages.extend([
                        {"role": m["role"], "content": m["content"]}
                        for m in st.session_state.messages
                    ])
                    
                    response = client.chat.completions.create(
                        model="gpt-4o",
                        messages=messages,
                        temperature=0.5,
                        max_tokens=1000
                    )
                    
                    assistant_response = response.choices[0].message.content
                    
                    # ë‹µë³€ ê²€ì¦
                    with st.expander("ë‹µë³€ ê²€ì¦ ê²°ê³¼ ë³´ê¸°"):
                        verification_result = verify_response(script, prompt, assistant_response)
                        st.markdown(verification_result)
                    
                    st.markdown(assistant_response)
                    
                    # ì–´ì‹œìŠ¤í„´íŠ¸ ë©”ì‹œì§€ ì €ì¥
                    st.session_state.messages.append(
                        {"role": "assistant", "content": assistant_response}
                    )
                    
                except Exception as e:
                    st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

if __name__ == "__main__":
    main() 
